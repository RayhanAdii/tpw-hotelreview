{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb5a9f5-670e-4ff0-91dd-e9e071f70126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65fcc040-d0dc-4492-b09b-9669f38456c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./dataset/train_preprocessed_v6.csv\")\n",
    "df_train['review_text'] = df_train['review_text'].apply(ast.literal_eval)\n",
    "\n",
    "df_test = pd.read_csv(\"./dataset/test_preprocessed_v6.csv\")\n",
    "df_test['review_text'] = df_test['review_text'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4367eb5-89f0-4faf-8693-e7d02fb0d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7989abe3-b490-4757-a257-d5f1162b7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 278435/278435 [00:01<00:00, 149073.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 278436/278436 [00:01<00:00, 156413.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Put Back Together\n",
    "\n",
    "def stringify(df):\n",
    "    sentences = []\n",
    "    \n",
    "    for i in tqdm(range(len(df['review_text']))):\n",
    "        # Perform the desired manipulation\n",
    "        value = df['review_text'][i]\n",
    "\n",
    "        sentence = \"\"\n",
    "        \n",
    "        for word in value:\n",
    "            sentence += word\n",
    "            sentence += \" \"\n",
    "\n",
    "        sentences.append(sentence)\n",
    "    \n",
    "    # Change the value in place\n",
    "    df[\"review_text\"]= sentences\n",
    "\n",
    "stringify(df_train)\n",
    "stringify(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9a7487-31cd-4090-a053-d5afb452964c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>hotel_location</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_language</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>hotel_rating_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cobblestone Inn Suites-eads</td>\n",
       "      <td>Eads US</td>\n",
       "      <td>3mcTZLLqVE5ztNyE</td>\n",
       "      <td>28-11-2015</td>\n",
       "      <td>new hotel great staff loved interacting peggy ...</td>\n",
       "      <td>en</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DoubleTree by Hilton London Islington</td>\n",
       "      <td>London 9LA United Kingdom</td>\n",
       "      <td>7HCg4Hk7ZbpQY60X</td>\n",
       "      <td>29-12-2015</td>\n",
       "      <td>lovely attentive welcoming staff clean comfort...</td>\n",
       "      <td>en</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.770199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>citizenM Tower of London</td>\n",
       "      <td>London United Kingdom</td>\n",
       "      <td>yABlhfdJX4UlnNqA</td>\n",
       "      <td>08-09-2016</td>\n",
       "      <td>cozy space chill myouch variety food available</td>\n",
       "      <td>en</td>\n",
       "      <td>7.1</td>\n",
       "      <td>9.133295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The Savoy</td>\n",
       "      <td>London United Kingdom</td>\n",
       "      <td>hS252WXcgeRVdch6</td>\n",
       "      <td>15-10-2011</td>\n",
       "      <td>hotel ha certainly benefited investment owner ...</td>\n",
       "      <td>en</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.309445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Millennium Gloucester Hotel London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fo44un6pn2M7XoVJ</td>\n",
       "      <td>23-10-2015</td>\n",
       "      <td>excellent location albert hall place eat staye...</td>\n",
       "      <td>en</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.646234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                             hotel_name  \\\n",
       "0             0           0            Cobblestone Inn Suites-eads   \n",
       "1             1           1  DoubleTree by Hilton London Islington   \n",
       "2             2           2               citizenM Tower of London   \n",
       "3             3           3                              The Savoy   \n",
       "4             4           4     Millennium Gloucester Hotel London   \n",
       "\n",
       "              hotel_location         review_id review_date  \\\n",
       "0                    Eads US  3mcTZLLqVE5ztNyE  28-11-2015   \n",
       "1  London 9LA United Kingdom  7HCg4Hk7ZbpQY60X  29-12-2015   \n",
       "2      London United Kingdom  yABlhfdJX4UlnNqA  08-09-2016   \n",
       "3      London United Kingdom  hS252WXcgeRVdch6  15-10-2011   \n",
       "4                        NaN  Fo44un6pn2M7XoVJ  23-10-2015   \n",
       "\n",
       "                                         review_text review_language  \\\n",
       "0  new hotel great staff loved interacting peggy ...              en   \n",
       "1  lovely attentive welcoming staff clean comfort...              en   \n",
       "2    cozy space chill myouch variety food available               en   \n",
       "3  hotel ha certainly benefited investment owner ...              en   \n",
       "4  excellent location albert hall place eat staye...              en   \n",
       "\n",
       "   review_rating  hotel_rating_mean  \n",
       "0            8.0           8.000000  \n",
       "1           10.0           8.770199  \n",
       "2            7.1           9.133295  \n",
       "3           10.0           9.309445  \n",
       "4           10.0           7.646234  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd01963-274e-4ca4-819b-f2166f6d7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation = train_test_split(df_train, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8902b7-91f3-4703-a17f-ab58b8baae39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new hotel great staff loved interacting peggy wish salad vegetable option good menyou room clean nicely decorated trip advisor yoyou write 200 word '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.review_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4b06b-cda0-4199-b7f7-4e400a64e403",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfe25e-495f-46d0-9e9e-b4e3c6058248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f94584-4c78-4972-bb16-bf3dd6cdc5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c52c017c-3c51-4fa3-acfc-39fa654ce861",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e6dcf4-1192-46d3-9558-bf0647df6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUT_DIR = './models/bert_regressor'\n",
    "## Model Configurations\n",
    "MAX_LEN_TRAIN = 88\n",
    "MAX_LEN_VALID = 88\n",
    "MAX_LEN_TEST = 88\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 10\n",
    "NUM_THREADS = 1  ## Number of threads for collecting dataset\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "\n",
    "if not os.path.isdir(MODEL_OUT_DIR):\n",
    "    os.makedirs(MODEL_OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee07a45-4aac-45e7-9466-efefe0f2ff5b",
   "metadata": {},
   "source": [
    "## Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28471f3e-9722-4e08-bf4e-473840c6fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Excerpt_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, maxlen, tokenizer): \n",
    "        #Store the contents of the file in a pandas dataframe\n",
    "        self.df = data.reset_index()\n",
    "        #Initialize the tokenizer for the desired transformer model\n",
    "        self.tokenizer = tokenizer\n",
    "        #Maximum length of the tokens list to keep all the sequences of fixed size\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        #Select the sentence and label at the specified index in the data frame\n",
    "        excerpt = self.df.loc[index, 'review_text']\n",
    "        try:\n",
    "            target = self.df.loc[index, 'target']\n",
    "        except:\n",
    "            target = 0.0\n",
    "        identifier = self.df.loc[index, 'review_id']\n",
    "        #Preprocess the text to be suitable for the transformer\n",
    "        tokens = self.tokenizer.tokenize(excerpt) \n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]'] \n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] \n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] \n",
    "        #Obtain the indices of the tokens in the BERT Vocabulary\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens) \n",
    "        input_ids = torch.tensor(input_ids) \n",
    "        #Obtain the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attention_mask = (input_ids != 0).long()\n",
    "        \n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "        return input_ids, attention_mask, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e3aba5-a820-4ac8-83c2-29772874a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRegresser(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        #The output layer that takes the [CLS] representation and gives an output\n",
    "        self.cls_layer1 = nn.Linear(config.hidden_size,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.ff1 = nn.Linear(128,128)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.ff2 = nn.Linear(128,1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        #Feed the input to Bert model to obtain contextualized representations\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #Obtain the representations of [CLS] heads\n",
    "        logits = outputs.last_hidden_state[:,0,:]\n",
    "        output = self.cls_layer1(logits)\n",
    "        output = self.relu1(output)\n",
    "        output = self.ff1(output)\n",
    "        output = self.tanh1(output)\n",
    "        output = self.ff2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e67a1f-5503-4bc6-b95a-9903407082b0",
   "metadata": {},
   "source": [
    "## Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "416c89ed-936d-475e-8b40-19234bd39259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n",
    "    best_acc = 0\n",
    "    for epoch in trange(epochs, desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for i, (input_ids, attention_mask, target) in enumerate(iterable=train_loader):\n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            \n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            loss = criterion(output, target.type_as(output))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        print(f\"Training loss is {train_loss/len(train_loader)}\")\n",
    "        val_loss = evaluate(model=model, criterion=criterion, dataloader=val_loader, device=device)\n",
    "        print(\"Epoch {} complete! Validation Loss : {}\".format(epoch, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78127d77-2a7d-42de-b384-a8d129927103",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc8daca-5f9f-4734-9e16-31bdcadfa274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    mean_acc, mean_loss, count = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "            \n",
    "            mean_loss += criterion(output, target.type_as(output)).item()\n",
    "#             mean_err += get_rmse(output, target)\n",
    "            count += 1\n",
    "            \n",
    "    return mean_loss/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062a67f9-9df0-483d-8eee-1da49e758927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(output, target):\n",
    "    err = torch.sqrt(metrics.mean_squared_error(target, output))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3c0c4c-94d2-4cf4-8d54-21bdce5ecb34",
   "metadata": {},
   "source": [
    "## Predict Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a47ebe-73b3-4166-86a7-2e0c70fe60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    predicted_label = []\n",
    "    actual_label = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output = model(input_ids, attention_mask)\n",
    "                        \n",
    "            predicted_label += output\n",
    "            actual_label += target\n",
    "            \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e7b1e1-c382-4cc5-8a83-406fa58c7f84",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f29295b-89a8-4498-9ebe-6578346daa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertRegresser: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertRegresser from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertRegresser from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertRegresser were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls_layer1.bias', 'ff1.bias', 'ff2.weight', 'ff1.weight', 'ff2.bias', 'cls_layer1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Configuration loaded from AutoConfig \n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "## Tokenizer loaded from AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "## Creating the model from the desired transformer model\n",
    "model = BertRegresser.from_pretrained(MODEL_NAME, config=config)\n",
    "## GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "## Putting model to device\n",
    "model = model.to(device)\n",
    "## Takes as the input the logits of the positive class and computes the binary cross-entropy \n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()\n",
    "## Optimizer\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc5812-9d0c-44b7-bba6-3dabb1d2e053",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50827400-4767-4d18-8e5b-d8e6140e8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Dataset\n",
    "train_set = Excerpt_Dataset(data=train_data, maxlen=MAX_LEN_TRAIN, tokenizer=tokenizer)\n",
    "valid_set = Excerpt_Dataset(data=validation, maxlen=MAX_LEN_VALID, tokenizer=tokenizer)\n",
    "test_set = Excerpt_Dataset(data=df_test, maxlen=MAX_LEN_TEST, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "## Data Loaders\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, num_workers=NUM_THREADS)\n",
    "\n",
    "# print(len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f7a86-6daa-47e4-947e-2555d541debe",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa2b2e-7e4b-43d0-aca4-d62057e643f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(model=model, \n",
    "      criterion=criterion,\n",
    "      optimizer=optimizer, \n",
    "      train_loader=train_loader,\n",
    "      val_loader=valid_loader,\n",
    "      epochs = 10,\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087c48f-3730-44f0-8f37-f517ed4df574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
